# ðŸ§â€â™‚ï¸ðŸ“¸ Human Activity Recognition (HAR) from Images

This project performs **Human Activity Recognition** using **image data**. It uses machine learning (or deep learning) to classify images into categories like walking, sitting, standing, etc., based on visual features.

## ðŸ“¦ Project Structure

â”œâ”€â”€ data/ # Folder for image datasets (train/val/test)
â”œâ”€â”€ models/ # Trained model files
â”œâ”€â”€ app.py # Streamlit app (visual demo)
â”œâ”€â”€ main.py # Model training and evaluation
â”œâ”€â”€ utils.py # Helper functions
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # You're reading this :)


## ðŸ§  Activities Recognized

- ðŸš¶â€â™‚ï¸ WALKING  
- ðŸ§ STANDING  
- ðŸª‘ SITTING  
- ðŸ›Œ LAYING  
- ðŸ§— WALKING_UPSTAIRS  
- â¬‡ï¸ WALKING_DOWNSTAIRS  

## ðŸ–¼ï¸ Dataset

We use a dataset of labeled human activity images. Examples may come from public sources or be custom-collected.

> **Alternative**: You can also adapt sensor-based datasets (e.g., UCI HAR) to synthetic images using plotting or pose estimation models.

## ðŸ“Š Model

- CNN-based image classifier (e.g., `ResNet`, `MobileNet`, or custom CNN)
- Trained using PyTorch or TensorFlow
- Metrics: accuracy, precision, recall, F1-score

## ðŸš€ How to Run

1. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
2. **Train the model** 
python main.py

3. **Launch Streamlit app:**
streamlit run app.py


ðŸ’¡ Features

    Upload your own activity images and get predictions in real time

    Visualize model performance

    Extendable for more activity classes

